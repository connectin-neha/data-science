{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2d211ac-e216-4e56-8ec1-351bcae7f3fc",
   "metadata": {},
   "source": [
    "# spaCy\n",
    "\n",
    "spaCy is a free and open-source library for NLP in Python, which is designed to simplify building systems for information extraction. spaCy provides production-ready code widely used for NLP use cases. It supports 64+ languages. It is robust, fast and has built-in visualizers for various NLP functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95f5dc0-981b-44df-8190-e594f68de0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b868b811-c101-4f1e-bb03-75e4a39b6269",
   "metadata": {},
   "source": [
    "#### en_core_web_sm\n",
    "\n",
    "<b>en_core_web_sm</b> is a pre-trained small English language model provided by spaCy. It is designed to support tasks like part-of-speech tagging, dependency parsing, named entity recognition (NER), and tokenization in English text.\n",
    "\n",
    "It can be installed with following command\n",
    "\n",
    "*python -m spacy download en_core_web_sm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b24c00-a51e-42e1-a700-03c5298a5cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load en_core_web_sm for further processing\n",
    "# Let us run spaCy nlp pipeline for text processing which returns a language object\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad2dfe0c-525e-4a54-921b-aeb137cbaafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ec99583-628b-412e-8291-0a7591850ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us process a sample string with spaCy\n",
    "\n",
    "text = 'We are learning spaCy for Natural Language Processing'\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b5cc49b-e4da-47bd-96f9-fe7938016c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c808480-1a3b-4b56-907d-c937d7130417",
   "metadata": {},
   "source": [
    "#### As we see above, nlp object converts the text ino a Doc object(container) which contains tokens, linguistic annotations, relationships, etc of the processes text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38edba7d-e717-4f7b-af04-e4b525af9f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We are learning spaCy for Natural Language Processing'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862f4cb6-446a-4974-8832-deb3de2b3174",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b33ff70-22cf-4f0e-a7de-b8a99dd9ed35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', 'are', 'learning', 'spaCy', 'for', 'Natural', 'Language', 'Processing']\n"
     ]
    }
   ],
   "source": [
    "# Let us look at the tokens created\n",
    "print([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d7bd01-6a80-4dbc-9038-afdc52028564",
   "metadata": {},
   "source": [
    "#### Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dea80982-942c-4788-a279-d082ea71e0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We are learning NLP.', 'We are getting introduced to spaCy.']\n"
     ]
    }
   ],
   "source": [
    "doc =  nlp('We are learning NLP. We are getting introduced to spaCy.')\n",
    "\n",
    "print([sent.text for sent in doc.sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bdf739e-3784-4367-9186-bfb48fbbf5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence is \"We are learning NLP.\" with length 5\n",
      "Sentence is \"We are getting introduced to spaCy.\" with length 7\n"
     ]
    }
   ],
   "source": [
    "# print sentence and length of each sentence\n",
    "\n",
    "doc =  nlp('We are learning NLP. We are getting introduced to spaCy.')\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print('Sentence is \"{0}\" with length {1}'.format(sent.text,len(sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c2724-5ab7-4c9c-9e46-3518324c2997",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c61dc3b8-e643-4df8-9393-05f62524d769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:  We  Lemma:  we\n",
      "Token:  are  Lemma:  be\n",
      "Token:  learning  Lemma:  learn\n",
      "Token:  NLP  Lemma:  NLP\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('We are learning NLP')\n",
    "\n",
    "for token in doc:\n",
    "    print('Token: ',token.text,' Lemma: ', token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bda3a2f-3199-4ec7-a24e-f9edf141b959",
   "metadata": {},
   "source": [
    "#### POS(part of speech) tagging with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "261a7b5e-8d3a-46a5-964f-5418bbd40873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: I, POS: PRON, POS Explaination: pronoun\n",
      "Token: watch, POS: VERB, POS Explaination: verb\n",
      "Token: TV, POS: NOUN, POS Explaination: noun\n",
      "Token: ., POS: PUNCT, POS Explaination: punctuation\n"
     ]
    }
   ],
   "source": [
    "verb_sent = 'I watch TV.'\n",
    "\n",
    "for token in nlp(verb_sent):\n",
    "    print('Token: {0}, POS: {1}, POS Explaination: {2}'.format(token.text, token.pos_, spacy.explain(token.pos_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14b7913d-5915-443e-a034-56463c040944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: I, POS: PRON, POS Explaination: pronoun\n",
      "Token: left, POS: VERB, POS Explaination: verb\n",
      "Token: without, POS: ADP, POS Explaination: adposition\n",
      "Token: my, POS: PRON, POS Explaination: pronoun\n",
      "Token: watch, POS: NOUN, POS Explaination: noun\n",
      "Token: ., POS: PUNCT, POS Explaination: punctuation\n"
     ]
    }
   ],
   "source": [
    "# let us compare above processing with a sentence which has watch as noun\n",
    "noun_sent = 'I left without my watch.'\n",
    "\n",
    "for token in nlp(noun_sent):\n",
    "    print('Token: {0}, POS: {1}, POS Explaination: {2}'.format(token.text, token.pos_, spacy.explain(token.pos_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b17ec9-e722-48ff-a17d-3269d5c7eb64",
   "metadata": {},
   "source": [
    "#### Named Entity Recognition(NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef7e10b0-9a72-4a72-9dec-a1e6d90169fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Albert Einstein is PERSON with start position 0 and end position 15\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Albert Einstein was genius')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print('Text {0} is {1} with start position {2} and end position {3}'.format(ent.text, ent.label_, ent.start_char, ent.end_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e22e15e4-19e6-48e5-a3ee-a23d2291c304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Taj Mahal is PERSON with start position 0 and end position 9\n",
      "Text Agra is GPE with start position 16 and end position 20\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Taj Mahal is in Agra')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print('Text {0} is {1} with start position {2} and end position {3}'.format(ent.text, ent.label_, ent.start_char, ent.end_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53346630-e8ea-40b9-aea9-fe287ec278ba",
   "metadata": {},
   "source": [
    "So sometimes spacy NER fails to detect correctly as we saw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14bc060e-0046-4994-9860-73f0092ac97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Taj Mahal is PERSON with start position 0 and end position 9\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Taj Mahal is in agra')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print('Text {0} is {1} with start position {2} and end position {3}'.format(ent.text, ent.label_, ent.start_char, ent.end_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100453de-85ea-4304-aed6-7534637783ea",
   "metadata": {},
   "source": [
    "Also, if written in small letters it does not detect correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56673d9-5bbf-4f7c-b0d8-2f38dfb126cd",
   "metadata": {},
   "source": [
    "Alternative way of accessing entity types is from the token of doc object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e8078cd-7b8a-4c55-bb54-441d851201b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Albert is of type PERSON\n",
      "Token Einstein is of type PERSON\n",
      "Token was is of type \n",
      "Token genius is of type \n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Albert Einstein was genius')\n",
    "\n",
    "for token in doc:\n",
    "    print('Token {0} is of type {1}'.format(token.text, token.ent_type_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09751845-9c1a-4fe0-b8e8-ef6d6ee71025",
   "metadata": {},
   "source": [
    "For tokens which are not recognized as entity, will give empty value for token.ent_type_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b1b9e5-d442-465e-936f-dd924f982567",
   "metadata": {},
   "source": [
    "### displaCy\n",
    "\n",
    "spaCy is equipped with a modern visualizer <b>displaCy</b>. The displaCy entity visualizer highlights named entities and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ee978-4f68-439c-b26b-3a3af17a1085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nehaverma/Downloads/ENTER/lib/python3.12/site-packages/spacy/displacy/__init__.py:106: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Albert Einstein\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " was genius</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5001 ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp('Albert Einstein was genius')\n",
    "\n",
    "displacy.serve(doc, style='ent', port=5001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a883943-c545-445b-ad83-66dc7c7fc5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
