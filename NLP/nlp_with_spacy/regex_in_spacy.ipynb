{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "debc4a0e-c737-494a-a356-7c25484ef2ea",
   "metadata": {},
   "source": [
    "# RegEx in spaCy\n",
    "\n",
    "spaCy has quick ways to implement RegEx in three pipes: \n",
    "\n",
    "- Matcher\n",
    "- PhraseMatcher\n",
    "- EntityRuler\n",
    "\n",
    "Matcher and PhraseMatcher do not align the matched patterns as entities in the doc.ents. Thus we utilize EntityRuler to implement regular expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c20fc-7776-4c8a-b9f5-0d5d36ea03a1",
   "metadata": {},
   "source": [
    "### 1. RegEx with EntityRuler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709c4675-d528-4dbc-8459-680fedaef9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e357e17a-6954-4684-96d9-7afab3ce2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us see an example\n",
    "\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "patterns = [{'label':'PHONE_NUMBER', 'pattern': [{'SHAPE':'ddd'},{'ORTH':'-'},{'SHAPE':'ddd'},{'ORTH':'-'},{'SHAPE':'dddd'}]}]\n",
    "\n",
    "ruler = nlp.add_pipe('entity_ruler')\n",
    "\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059ea6df-d9a8-4e6c-90db-9946b820aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Our phone number is 832-123-5555 and their phone number is 425-123-3829.'\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68d9423a-b46a-472b-a35b-dce42604c138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('832-123-5555', 'PHONE_NUMBER'), ('425-123-3829', 'PHONE_NUMBER')]\n"
     ]
    }
   ],
   "source": [
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b1a1ad-0d42-466c-84ac-efa2e8b7f9f1",
   "metadata": {},
   "source": [
    "Another Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7615d564-dc2a-44b8-8b0f-64f65dafdd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('4251234567', 'PHONE_NUMBERS')]\n"
     ]
    }
   ],
   "source": [
    "text = \"Our phone number is 4251234567.\"\n",
    "\n",
    "patterns = [{\"label\": \"PHONE_NUMBERS\", \"pattern\": [{\"TEXT\": {\"REGEX\": r\"(\\d){10}\"}}]}]\n",
    "\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "doc = nlp(text)\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c4870ee-99fe-4df5-abbc-768783d1f11a",
   "metadata": {},
   "source": [
    "### 2. spaCy Matcher\n",
    "\n",
    "RegEx patterns are not trivial to read and debug. For these reasons, spaCy provides a readable, production-level, and maintainable alternative, the Matcher class. The Matcher class can match predefined rules to a sequence of tokens in Doc containers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d2f0aac-64d8-45e0-abdb-b9e328d9918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Matcher library\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b1707ce-494a-4de6-98da-7d33644c2d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp('Good Morning, this is our practice session on spaCy Matcher.')\n",
    "\n",
    "# initialize a matcher object\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3e0ddf7-5c94-4787-bcde-1cee46ca8a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pattern\n",
    "pattern = [{'LOWER':'good'},{'LOWER':'morning'}]\n",
    "\n",
    "# add the pattern to the matcer object\n",
    "matcher.add('morning_greeting',[pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1976abe6-d492-4825-a1f2-05a4e119469d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start token: 0 | End token: 2 | Matched text: Good Morning\n"
     ]
    }
   ],
   "source": [
    "# let us see if the pattern matches the text\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    print('Start token: {0} | End token: {1} | Matched text: {2}'.format(start,end,doc[start:end].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447f9332-dd3a-4d62-b0f8-37272547c081",
   "metadata": {},
   "source": [
    "The Matcher class allows patterns to be more expressive by allowing some operators inside the curly brackets. These operators are for extended comparison and look similar to Python's in, not in and comparison operators. The table shows a list of supported operators in the Matcher class.\n",
    "\n",
    "| Attribute        | Value Type | Description                              |\n",
    "|------------------|------------|------------------------------------------|\n",
    "| IN               | any type   | Attribute value is a member of a list    |\n",
    "| NOT_IN           | any type   | Attribute value is not a member of a list|\n",
    "| ==, >=, <=, >, < | int, float | Comparision operators                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9037fe6-3c03-4de5-b10f-f5761f547bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start token: 0 | End token: 2 | Matched text: Good morning\n",
      "Start token: 3 | End token: 5 | Matched text: good evening\n"
     ]
    }
   ],
   "source": [
    "# Let us see an example with operators\n",
    "doc = nlp('Good morning and good evening.')\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern = [{'LOWER':'good'},{'LOWER': {'IN':['morning','evening']}}]\n",
    "\n",
    "matcher.add('morning_greeting', [pattern])\n",
    "\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    print('Start token: {0} | End token: {1} | Matched text: {2}'.format(start,end,doc[start:end].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8842609f-3ecd-463f-aaab-c5c33f887e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start token: 0 | End token: 2 | Matched text: Good morning\n"
     ]
    }
   ],
   "source": [
    "# Let us see an example with operators\n",
    "doc = nlp('Good morning and good evening.')\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern = [{'LOWER':'good'},{'LOWER': {'NOT_IN':['day','evening']}}]\n",
    "\n",
    "matcher.add('morning_greeting', [pattern])\n",
    "\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    print('Start token: {0} | End token: {1} | Matched text: {2}'.format(start,end,doc[start:end].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c62bf-fa3f-40a5-8c55-f268cd90c123",
   "metadata": {},
   "source": [
    "### 3. spaCy PhraseMatcher \n",
    "\n",
    "While processing unstructured text, we often have long lists and dictionaries that we want to scan and match in given texts. The Matcher patterns are handcrafted and each token needs to be coded individually. If we have a long list of phrases, Matcher is no longer the best option. In this instance, PhraseMatcher class helps us match long dictionaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79a5978c-21f3-4b06-9856-ae838c6437ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4c9225f-2b13-4d46-8245-82aa74775c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create PhraseMatcher object \n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "# create patterns\n",
    "terms = ['Bill Gates', 'John Smith']\n",
    "patterns = [nlp.make_doc(term) for term in terms]\n",
    "\n",
    "matcher.add('PeopleOFInterest', patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e21f6ffc-35f4-4118-8671-bfb03d20bf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start token: 0 | End token: 2 | Matched text: Bill Gates\n"
     ]
    }
   ],
   "source": [
    "doc =  nlp('Bill Gates met John smith for an important discussion regarding importance of AI')\n",
    "\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    print('Start token: {0} | End token: {1} | Matched text: {2}'.format(start,end,doc[start:end].text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96a1b2e2-efe3-45d6-8d5a-b85eea448aa1",
   "metadata": {},
   "source": [
    "Above John Smith is not matched as by default the PhraseMatcher does exact matching of text. If we want to match lower cased patterns or utilize shape of a pattern for matching, we can use the attr (attribute) argument in the PhraseMatcher class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7d4bdd3-ae9b-4d61-b1b6-bd59fdbcb848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start token: 0 | End token: 2 | Matched text: Bill Gates\n",
      "Start token: 3 | End token: 5 | Matched text: John smith\n"
     ]
    }
   ],
   "source": [
    "# Let us see an example of case insensitive matching\n",
    "\n",
    "#create matcher object with attr as LOWER\n",
    "matcher = PhraseMatcher(nlp.vocab, attr = 'lower')\n",
    "\n",
    "# create patterns\n",
    "terms = ['Bill Gates', 'John Smith']\n",
    "patterns = [nlp.make_doc(term) for term in terms]\n",
    "\n",
    "matcher.add('PeopleOFInterest', patterns)\n",
    "\n",
    "doc =  nlp('Bill Gates met John smith for an important discussion regarding importance of AI')\n",
    "\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    print('Start token: {0} | End token: {1} | Matched text: {2}'.format(start,end,doc[start:end].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1863832-9c5d-4c8b-bd4c-b3ca7fbd9ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start token: 5 | End token: 6 | Matched text: 9173928731\n"
     ]
    }
   ],
   "source": [
    "# Another example\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab, attr = 'shape')\n",
    "\n",
    "terms = ['9971729811']\n",
    "\n",
    "patterns = [nlp.make_doc(term) for term in terms]\n",
    "\n",
    "matcher.add('PhoneNumber', patterns)\n",
    "\n",
    "doc =  nlp(\"John's phone number is 9173928731\")\n",
    "\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    print('Start token: {0} | End token: {1} | Matched text: {2}'.format(start,end,doc[start:end].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a417092-f7ed-4f5c-8ac9-8741f9111c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
