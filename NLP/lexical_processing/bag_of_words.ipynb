{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f1ba77-e271-4422-8a78-8fe6112cb673",
   "metadata": {},
   "source": [
    "# Bag of Words Representation/Model\n",
    "\n",
    "<b>The Bag of Words (BoW)</b> is a simple and commonly used model in natural language processing (NLP) to represent text data for machine learning. It transforms text into a format that algorithms can work with, particularly by counting the frequency of words in a given set of documents.\n",
    "\n",
    "Key Concepts of Bag of Words:\n",
    "\n",
    "- <b>Vocabulary:</b> This refers to the set of unique words that appear in the corpus (collection of documents). Each word in the vocabulary becomes a column in the resulting matrix.\n",
    "\n",
    "- <b>Document Representation:</b> Each document in the corpus is represented as a vector, where each element corresponds to the frequency of a word from the vocabulary. If a word does not appear in the document, its frequency will be zero.\n",
    "\n",
    "- <b>Order Ignorance:</b> The Bag of Words model ignores the order of words in the text. It only counts the occurrence of each word without considering the context or sequence in which the words appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf17aa6-18fb-407a-815d-469e64e4f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd95a23-2842-48b6-820a-4ff29f48f341",
   "metadata": {},
   "source": [
    "### Basic Bag of Words Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d047c01e-d2e6-4fc0-a10a-ddc22657ab67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gangs of Wasseypur is a great movie.', 'The success of a movie depends on the performance of the actors.', 'There are no new movies releasing this week.']\n"
     ]
    }
   ],
   "source": [
    "documents = [\"Gangs of Wasseypur is a great movie.\", \"The success of a movie depends on the performance of the actors.\", \"There are no new movies releasing this week.\"]\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a400d15-9a03-4492-9262-39230f1ffc56",
   "metadata": {},
   "source": [
    "#### Let us define a method for preprocessing the document/text. Steps are\n",
    "\n",
    "- convert the text to lower/upper case (preferred lower case) to make the words case insensitive\n",
    "- tokenise the text into words\n",
    "- remove the stop words\n",
    "- re-join the tokenised words into a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0945f320-d877-4bef-851f-3324efbbf541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(document):\n",
    "\n",
    "    # convert document text to lower\n",
    "    document = document.lower()\n",
    "\n",
    "    # tokenise the text into words\n",
    "    words = word_tokenize(document)\n",
    "\n",
    "    # remove the stop words\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "\n",
    "    # rejoin the words to make sentence without stop words\n",
    "    document = ' '.join(words)\n",
    "\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e27bd9cc-73cc-4362-8cb8-69348e755a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gangs wasseypur great movie .', 'success movie depends performance actors .', 'new movies releasing week .']\n"
     ]
    }
   ],
   "source": [
    "# Let is pre-process the documents\n",
    "documents = [preprocess(document) for document in documents]\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4e9ef-197b-4b04-855a-7dd9774e45af",
   "metadata": {},
   "source": [
    "#### Creating bag of words using count vectorizer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b793de3c-d842-452e-9926-514fbcfddd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 13 stored elements and shape (3, 12)>\n",
      "  Coords\tValues\n",
      "  (0, 2)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 11)\t1\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow_model = vectorizer.fit_transform(documents)\n",
    "print(bow_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e553be39-e385-4b87-8374-e1e0a96f7a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 1 0 0 0 0 0 1 0]\n",
      " [1 1 0 0 1 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 0 1 1 0 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# print the full sparse matrix\n",
    "print(bow_model.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ff566e0-0305-47ee-8cd6-9354a1530be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 12)\n"
     ]
    }
   ],
   "source": [
    "print(bow_model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fa741ce-1e4d-4701-a2e1-8c4b699d44f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['actors' 'depends' 'gangs' 'great' 'movie' 'movies' 'new' 'performance'\n",
      " 'releasing' 'success' 'wasseypur' 'week']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c023d3-2587-4db3-a2a3-3b6b4bbea4c6",
   "metadata": {},
   "source": [
    "### Create Bag of Words for Spam-Ham Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f606b92-8afd-4b09-b125-57c2e2e85732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file\n",
    "spam_ham_text = pd.read_csv('SMSSpamCollection.txt', delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dba4acb8-7807-4a81-9a7a-f980934ccf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_ham_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "421ee050-fe27-4f50-a026-ee8e6ca97cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_ham_text.columns = ['label','message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a5f71de-5fe6-46f5-acb9-e2e9fb022ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_ham_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "907492e1-1984-40c7-be9a-69312cd303d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_ham_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9012976a-ce1d-4e55-81e6-7939d7f771b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    5572 non-null   object\n",
      " 1   message  5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "spam_ham_text.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d6c0b39-a991-4015-9a47-734ad4894839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking only first 50 records from the entire data frame\n",
    "spam_ham_text = spam_ham_text.iloc[0:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e164b59-6254-44a0-8a51-857fd30bb71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_ham_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9efd5446-6fd3-4d49-906e-760fa93afa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = spam_ham_text.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "262de2ec-47f7-4e05-9800-d2fcf3d526dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b654590e-ffec-445f-bf30-f505317a37b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets convert the messages to list for preprocessing\n",
    "messages = [message for message in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46380dc2-b280-4d6e-9b16-750dbf031706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "019b96df-0157-49b6-b064-52b184e1d733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go jurong point , crazy .. available bugis n great world la e buffet ... cine got amore wat ...', 'ok lar ... joking wif u oni ...', \"free entry 2 wkly comp win fa cup final tkts 21st may 2005. text fa 87121 receive entry question ( std txt rate ) & c 's apply 08452810075over18 's\", 'u dun say early hor ... u c already say ...', \"nah n't think goes usf , lives around though\", \"freemsg hey darling 's 3 week 's word back ! 'd like fun still ? tb ok ! xxx std chgs send , £1.50 rcv\", 'even brother like speak . treat like aids patent .', \"per request 'melle melle ( oru minnaminunginte nurungu vettam ) ' set callertune callers . press * 9 copy friends callertune\", 'winner ! ! valued network customer selected receivea £900 prize reward ! claim call 09061701461. claim code kl341 . valid 12 hours .', 'mobile 11 months ? u r entitled update latest colour mobiles camera free ! call mobile update co free 08002986030', \"'m gon na home soon n't want talk stuff anymore tonight , k ? 've cried enough today .\", 'six chances win cash ! 100 20,000 pounds txt > csh11 send 87575. cost 150p/day , 6days , 16+ tsandcs apply reply hl 4 info', 'urgent ! 1 week free membership £100,000 prize jackpot ! txt word : claim : 81010 & c www.dbuk.net lccltd pobox 4403ldnw1a7rw18', \"'ve searching right words thank breather . promise wont take help granted fulfil promise . wonderful blessing times .\", 'date sunday ! !', 'xxxmobilemovieclub : use credit , click wap link next txt message click > > http : //wap . xxxmobilemovieclub.com ? n=qjkgighjjgcbl', \"oh k ... 'm watching : )\", 'eh u remember 2 spell name ... yes . v naughty make v wet .', 'fine that\\x92s way u feel . that\\x92s way gota b', 'england v macedonia - dont miss goals/team news . txt ur national team 87077 eg england 87077 try : wales , scotland 4txt/ú1.20 poboxox36504w45wq 16+', 'seriously spell name ?', '‘ going try 2 months ha ha joking', 'ü pay first lar ... da stock comin ...', 'aft finish lunch go str lor . ard 3 smth lor . u finish ur lunch already ?', 'ffffffffff . alright way meet sooner ?', \"forced eat slice . 'm really hungry tho . sucks . mark getting worried . knows 'm sick turn pizza . lol\", 'lol always convincing .', \"catch bus ? frying egg ? make tea ? eating mom 's left dinner ? feel love ?\", \"'m back & amp ; 're packing car , 'll let know 's room\", 'ahhh . work . vaguely remember ! feel like ? lol', \"wait 's still clear , sure sarcastic 's x n't want live us\", \"yeah got 2 v apologetic . n fallen actin like spoilt child got caught . till 2 ! wo n't go ! badly cheers . ?\", 'k tell anything .', 'fear fainting housework ? quick cuppa', 'thanks subscription ringtone uk mobile charged £5/month please confirm replying yes . reply charged', 'yup ... ok go home look timings msg ü ... xuhui going learn 2nd may lesson 8am', \"oops , 'll let know roommate 's done\", 'see letter b car', 'anything lor ... u decide ...', \"hello ! 's saturday go ? texting see 'd decided anything tomo . 'm trying invite anything !\", 'pls go ahead watts . wanted sure . great weekend . abiola', 'forget tell ? want , need , crave ... ... love sweet arabian steed ... mmmmmm ... yummy', '07732584351 - rodger burns - msg = tried call reply sms free nokia mobile + free camcorder . please call 08000930705 delivery tomorrow', 'seeing ?', 'great ! hope like man well endowed . & lt ; # & gt ; inches ...', 'calls .. messages .. missed calls', \"n't get hep b immunisation nigeria .\", 'fair enough , anything going ?', \"yeah hopefully , tyler ca n't could maybe ask around bit\", \"u n't know stubborn . n't even want go hospital . kept telling mark 'm weak sucker . hospitals weak suckers .\", 'thinked . first time saw class .', 'gram usually runs like & lt ; # & gt ; , half eighth smarter though gets almost whole second gram & lt ; # & gt ;', \"k fyi x ride early tomorrow morning 's crashing place tonight\", \"wow . never realized embarassed accomodations . thought liked , since best could always seemed happy `` cave '' . 'm sorry n't n't give . 'm sorry offered . 'm sorry room embarassing .\", 'sms . ac sptv : new jersey devils detroit red wings play ice hockey . correct incorrect ? end ? reply end sptv', 'know mallika sherawat yesterday ? find @ & lt ; url & gt ;', 'congrats ! 1 year special cinema pass 2 . call 09061209465 ! c suprman v , matrix3 , starwars3 , etc 4 free ! bx420-ip4-5we . 150pm . dont miss !', \"sorry , 'll call later meeting .\", 'tell reached', 'yes .. gauti sehwag odi series .', \"gon na pick $ 1 burger way home . ca n't even move . pain killing .\", 'ha ha ha good joke . girls situation seekers .', 'part checking iq', 'sorry roommates took forever , ok come ?', 'ok lar double check wif da hair dresser already said wun cut v short . said cut look nice .', 'valued customer , pleased advise following recent review mob . awarded £1500 bonus prize , call 09066364589', \"today `` song dedicated day .. '' song u dedicate ? send ur valuable frnds first rply ...\", 'urgent ur awarded complimentary trip eurodisinc trav , aco & entry41 £1000 . claim txt dis 87121 18+6 * £1.50 ( morefrmmob . shracomorsglsuplt ) 10 , ls1 3aj', \"hear new `` divorce barbie '' ? comes ken 's stuff !\", 'plane give month end .', 'wah lucky man ... save money ... hee ...', 'finished class .', 'hi babe im home wan na something ? xx', 'k .. k : ) ? performed ?', 'u call ...', 'waiting machan . call free .', 'thats cool . gentleman treat dignity respect .', 'like peoples much : ) shy pa .', 'operate & lt ; # & gt ;', \". still looking job . much ta 's earn .\", \"sorry , 'll call later\", 'k. call ah ?', 'ok way home hi hi', 'place man', 'yup next stop .', \"call later , n't network . urgnt , sms .\", \"real u getting yo ? need 2 tickets one jacket 'm done . already used multis .\", \"yes started send requests make pain came back 'm back bed . double coins factory . got ta cash nitros .\", \"'m really still tonight babe\", 'ela kano. , il download , come wen ur free ..', 'yeah ! ‘ stand close tho- ‘ catch something !', \"sorry pain . ok meet another night ? spent late afternoon casualty means n't done stuff42moro includes time sheets . sorry .\", 'smile pleasure smile pain smile trouble pours like rain smile sum1 hurts u smile becoz someone still loves see u smiling ! !', 'please call customer service representative 0800 169 6031 10am-9pm guaranteed £1000 cash £5000 prize !', 'havent planning buy later . check already lido got 530 show e afternoon . u finish work already ?', \"free ringtone waiting collected . simply text password `` mix '' 85069 verify . get usher britney . fml , po box 5249 , mk17 92h . 450ppw 16\", 'watching telugu movie .. wat abt u ?', 'see . finish loads loans pay', \"hi . wk ok - hols ! yes bit run . forgot hairdressers appointment four need get home n shower beforehand . cause prob u ? ''\", 'see cup coffee animation']\n"
     ]
    }
   ],
   "source": [
    "# Let us pre-process the messages\n",
    "messages = [preprocess(message) for message in messages]\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7091084-7a53-41f4-a3ad-32269bb60fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the messages\n",
    "vectorizer = CountVectorizer()\n",
    "bow_spam_ham = vectorizer.fit_transform(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cffef3f-baa5-4ca5-a5cb-c5177c05d83e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 884 stored elements and shape (100, 640)>\n",
      "  Coords\tValues\n",
      "  (0, 237)\t1\n",
      "  (0, 294)\t1\n",
      "  (0, 419)\t1\n",
      "  (0, 150)\t1\n",
      "  (0, 75)\t1\n",
      "  (0, 93)\t1\n",
      "  (0, 247)\t1\n",
      "  (0, 623)\t1\n",
      "  (0, 302)\t1\n",
      "  (0, 92)\t1\n",
      "  (0, 121)\t1\n",
      "  (0, 243)\t1\n",
      "  (0, 62)\t1\n",
      "  (0, 600)\t1\n",
      "  (1, 389)\t1\n",
      "  (1, 303)\t1\n",
      "  (1, 293)\t1\n",
      "  (1, 611)\t1\n",
      "  (1, 391)\t1\n",
      "  (2, 222)\t1\n",
      "  (2, 196)\t2\n",
      "  (2, 616)\t1\n",
      "  (2, 138)\t1\n",
      "  (2, 612)\t1\n",
      "  (2, 201)\t2\n",
      "  :\t:\n",
      "  (97, 469)\t1\n",
      "  (97, 320)\t1\n",
      "  (97, 321)\t1\n",
      "  (98, 389)\t1\n",
      "  (98, 266)\t1\n",
      "  (98, 634)\t1\n",
      "  (98, 373)\t1\n",
      "  (98, 232)\t1\n",
      "  (98, 85)\t1\n",
      "  (98, 262)\t1\n",
      "  (98, 615)\t1\n",
      "  (98, 265)\t1\n",
      "  (98, 458)\t1\n",
      "  (98, 220)\t1\n",
      "  (98, 252)\t1\n",
      "  (98, 70)\t1\n",
      "  (98, 221)\t1\n",
      "  (98, 484)\t1\n",
      "  (98, 83)\t1\n",
      "  (98, 112)\t1\n",
      "  (98, 424)\t1\n",
      "  (99, 154)\t1\n",
      "  (99, 469)\t1\n",
      "  (99, 130)\t1\n",
      "  (99, 64)\t1\n"
     ]
    }
   ],
   "source": [
    "print(bow_spam_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10d9901e-9838-4472-a5c7-8f96290d610e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bow_spam_ham.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fcf31ff-ab6a-465e-b87c-a22969b2864e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 640)\n",
      "['000' '07732584351' '0800' '08000930705' '08002986030'\n",
      " '08452810075over18' '09061209465' '09061701461' '09066364589' '10' '100'\n",
      " '1000' '10am' '11' '12' '1500' '150p' '150pm' '16' '169' '18' '20' '2005'\n",
      " '21st' '2nd' '3aj' '4403ldnw1a7rw18' '450ppw' '4txt' '50' '5000' '5249'\n",
      " '530' '5we' '6031' '6days' '81010' '85069' '87077' '87121' '87575' '8am'\n",
      " '900' '92h' '9pm' 'abiola' 'abt' 'ac' 'accomodations' 'aco' 'actin'\n",
      " 'advise' 'aft' 'afternoon' 'ah' 'ahead' 'ahhh' 'aids' 'almost' 'already'\n",
      " 'alright' 'always' 'amore' 'amp' 'animation' 'another' 'anymore'\n",
      " 'anything' 'apologetic' 'apply' 'appointment' 'arabian' 'ard' 'around'\n",
      " 'ask' 'available' 'awarded' 'babe' 'back' 'badly' 'barbie' 'becoz' 'bed'\n",
      " 'beforehand' 'best' 'bit' 'blessing' 'bonus' 'box' 'breather' 'britney'\n",
      " 'brother' 'buffet' 'bugis' 'burger' 'burns' 'bus' 'buy' 'bx420' 'ca'\n",
      " 'call' 'callers' 'callertune' 'calls' 'camcorder' 'came' 'camera' 'car'\n",
      " 'cash' 'casualty' 'catch' 'caught' 'cause' 'cave' 'chances' 'charged'\n",
      " 'check' 'checking' 'cheers' 'chgs' 'child' 'cine' 'cinema' 'claim'\n",
      " 'class' 'clear' 'click' 'close' 'co' 'code' 'coffee' 'coins' 'collected'\n",
      " 'colour' 'com' 'come' 'comes' 'comin' 'comp' 'complimentary' 'confirm'\n",
      " 'congrats' 'convincing' 'cool' 'copy' 'correct' 'cost' 'could' 'crashing'\n",
      " 'crave' 'crazy' 'credit' 'cried' 'csh11' 'cup' 'cuppa' 'customer' 'cut'\n",
      " 'da' 'darling' 'date' 'day' 'dbuk' 'decide' 'decided' 'dedicate'\n",
      " 'dedicated' 'delivery' 'detroit' 'devils' 'dignity' 'dinner' 'dis'\n",
      " 'divorce' 'done' 'dont' 'double' 'download' 'dresser' 'dun' 'early'\n",
      " 'earn' 'eat' 'eating' 'eg' 'egg' 'eh' 'eighth' 'ela' 'embarassed'\n",
      " 'embarassing' 'end' 'endowed' 'england' 'enough' 'entitled' 'entry'\n",
      " 'entry41' 'etc' 'eurodisinc' 'even' 'fa' 'factory' 'fainting' 'fair'\n",
      " 'fallen' 'fear' 'feel' 'ffffffffff' 'final' 'find' 'fine' 'finish'\n",
      " 'finished' 'first' 'fml' 'following' 'forced' 'forever' 'forget' 'forgot'\n",
      " 'four' 'free' 'freemsg' 'friends' 'frnds' 'frying' 'fulfil' 'fun' 'fyi'\n",
      " 'gauti' 'gentleman' 'get' 'gets' 'getting' 'girls' 'give' 'go' 'goals'\n",
      " 'goes' 'going' 'gon' 'good' 'got' 'gota' 'gram' 'granted' 'great' 'gt'\n",
      " 'guaranteed' 'ha' 'hair' 'hairdressers' 'half' 'happy' 'havent' 'hear'\n",
      " 'hee' 'hello' 'help' 'hep' 'hey' 'hi' 'hl' 'hockey' 'hols' 'home' 'hope'\n",
      " 'hopefully' 'hor' 'hospital' 'hospitals' 'hours' 'housework' 'http'\n",
      " 'hungry' 'hurts' 'ice' 'il' 'im' 'immunisation' 'inches' 'includes'\n",
      " 'incorrect' 'info' 'invite' 'ip4' 'iq' 'jacket' 'jackpot' 'jersey' 'job'\n",
      " 'joke' 'joking' 'jurong' 'kano' 'ken' 'kept' 'killing' 'kl341' 'know'\n",
      " 'knows' 'la' 'lar' 'late' 'later' 'latest' 'lccltd' 'learn' 'left'\n",
      " 'lesson' 'let' 'letter' 'lido' 'like' 'liked' 'link' 'live' 'lives' 'll'\n",
      " 'loads' 'loans' 'lol' 'look' 'looking' 'lor' 'love' 'loves' 'ls1' 'lt'\n",
      " 'lucky' 'lunch' 'macedonia' 'machan' 'make' 'mallika' 'man' 'mark'\n",
      " 'matrix3' 'may' 'maybe' 'means' 'meet' 'meeting' 'melle' 'membership'\n",
      " 'message' 'messages' 'minnaminunginte' 'miss' 'missed' 'mix' 'mk17'\n",
      " 'mmmmmm' 'mob' 'mobile' 'mobiles' 'mom' 'money' 'month' 'months'\n",
      " 'morefrmmob' 'morning' 'move' 'movie' 'msg' 'much' 'multis' 'na' 'nah'\n",
      " 'name' 'national' 'naughty' 'need' 'net' 'network' 'never' 'new' 'news'\n",
      " 'next' 'nice' 'nigeria' 'night' 'nitros' 'nokia' 'nurungu' 'odi'\n",
      " 'offered' 'oh' 'ok' 'one' 'oni' 'oops' 'operate' 'oru' 'pa' 'packing'\n",
      " 'pain' 'part' 'pass' 'password' 'patent' 'pay' 'peoples' 'per'\n",
      " 'performed' 'pick' 'pizza' 'place' 'plane' 'planning' 'play' 'please'\n",
      " 'pleased' 'pleasure' 'pls' 'po' 'pobox' 'poboxox36504w45wq' 'point'\n",
      " 'pounds' 'pours' 'press' 'prize' 'prob' 'promise' 'qjkgighjjgcbl'\n",
      " 'question' 'quick' 'rain' 'rate' 'rcv' 're' 'reached' 'real' 'realized'\n",
      " 'really' 'receive' 'receivea' 'recent' 'red' 'remember' 'reply'\n",
      " 'replying' 'representative' 'request' 'requests' 'respect' 'review'\n",
      " 'reward' 'ride' 'right' 'ringtone' 'rodger' 'room' 'roommate' 'roommates'\n",
      " 'rply' 'run' 'runs' 'said' 'sarcastic' 'saturday' 'save' 'saw' 'say'\n",
      " 'scotland' 'searching' 'second' 'see' 'seeing' 'seekers' 'seemed'\n",
      " 'sehwag' 'selected' 'send' 'series' 'seriously' 'service' 'set' 'sheets'\n",
      " 'sherawat' 'short' 'show' 'shower' 'shracomorsglsuplt' 'shy' 'sick'\n",
      " 'simply' 'since' 'situation' 'six' 'slice' 'smarter' 'smile' 'smiling'\n",
      " 'sms' 'smth' 'someone' 'something' 'song' 'soon' 'sooner' 'sorry' 'speak'\n",
      " 'special' 'spell' 'spent' 'spoilt' 'sptv' 'stand' 'started' 'starwars3'\n",
      " 'std' 'steed' 'still' 'stock' 'stop' 'str' 'stubborn' 'stuff'\n",
      " 'stuff42moro' 'subscription' 'sucker' 'suckers' 'sucks' 'sum1' 'sunday'\n",
      " 'suprman' 'sure' 'sweet' 'ta' 'take' 'talk' 'tb' 'tea' 'team' 'tell'\n",
      " 'telling' 'telugu' 'text' 'texting' 'thank' 'thanks' 'that' 'thats'\n",
      " 'think' 'thinked' 'tho' 'though' 'thought' 'tickets' 'till' 'time'\n",
      " 'times' 'timings' 'tkts' 'today' 'tomo' 'tomorrow' 'tonight' 'took'\n",
      " 'trav' 'treat' 'tried' 'trip' 'trouble' 'try' 'trying' 'tsandcs' 'turn'\n",
      " 'txt' 'tyler' 'uk' 'update' 'ur' 'urgent' 'urgnt' 'url' 'us' 'use' 'used'\n",
      " 'usf' 'usher' 'usually' 'vaguely' 'valid' 'valuable' 'valued' 've'\n",
      " 'verify' 'vettam' 'wah' 'wait' 'waiting' 'wales' 'wan' 'want' 'wanted'\n",
      " 'wap' 'wat' 'watching' 'watts' 'way' 'weak' 'week' 'weekend' 'well' 'wen'\n",
      " 'wet' 'whole' 'wif' 'win' 'wings' 'winner' 'wk' 'wkly' 'wo' 'wonderful'\n",
      " 'wont' 'word' 'words' 'work' 'world' 'worried' 'wow' 'wun' 'www' 'xuhui'\n",
      " 'xx' 'xxx' 'xxxmobilemovieclub' 'yeah' 'year' 'yes' 'yesterday' 'yo'\n",
      " 'yummy' 'yup' 'ú1']\n"
     ]
    }
   ],
   "source": [
    "print(bow_spam_ham.shape)\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114fdc51-1f9f-48a5-8835-83dd2f8f5bb9",
   "metadata": {},
   "source": [
    "#### A lot of duplicate tokens such as 'win'and 'winner'; 'reply' and 'replying'; 'want' and 'wanted' etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2620e36-a33d-42a6-88eb-4cbfae6ac9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
